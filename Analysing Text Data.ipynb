{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step01 -- Initializing Spark\n",
    "\n",
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# We add this line to avoid an error : \"Cannot run multiple SparkContexts at once\". \n",
    "# If there is an existing spark context, we will reuse it instead of creating a new context.\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# local[*]: run Spark locally with as many working processors as logical cores on your machine.\n",
    "# In the field of `master`, we use a local server with as many working processors (or threads) as possible (i.e. `local[*]`). \n",
    "# If we want Spark to run locally with 'k' worker threads, we can specify as `local[k]`.\n",
    "# The `appName` field is a name to be shown on the Sparking cluster UI. \n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[*]\", appName=\"FIT5202 Assignment 1 Part-A\")\n",
    "\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step02 -- Create RDD's\n",
    "\n",
    "#Renamed \"Agile Processess in Software Engineering and Extreme Programming\" as Agile.txt\n",
    "#Renamed \"Scrum Handbook\" as Scrum.txt\n",
    "\n",
    "agileRdd = sc.textFile('Agile.txt') #read agile text file\n",
    "scrumRdd = sc.textFile('Scrum.txt') #read scrum text file\n",
    "\n",
    "#To display number of lines\n",
    "\n",
    "print(\"Number of lines in Agile Processess in Software Engineering and Extreme Programming are \",agileRdd.count())\n",
    "print(\"Number of lines in Scrum Handbook are \",scrumRdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 03 -- Cleaning and Manipulating text\n",
    "\n",
    "#Import re package to use regex\n",
    "import re  \n",
    "\n",
    "def function(inputRDD):\n",
    "    if(inputRDD!=\" \"):\n",
    "        regex = re.compile('[^a-zA-Z \\s]')  #1 To validate the characters present in RDD\n",
    "        chkRegex=regex.sub('',inputRDD)\n",
    "        value = chkRegex.lower()            #2 To convert characters into lower case\n",
    "    return value.strip()                    #3 To removing trailing spaces\n",
    "     \n",
    "newAgileRDD=agileRdd.map(function)\n",
    "newAgileRDD1=newAgileRDD.filter(lambda x:x!='') # To remove the empty '' element from RDD\n",
    "print(\"New Agile result: \\n\",newAgileRDD1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 03 -- Cleaning and Manipulating text for Scrum file\n",
    "\n",
    "newScrumRDD=scrumRdd.map(function)\n",
    "newScrumRDD1=newScrumRDD.filter(lambda x:x!='')  # To remove the empty '' element from RDD\n",
    "print(\"New Scrum result: \\n\",newScrumRDD1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 04 -- Transformation and Action for Agile\n",
    "\n",
    "agileWords = newAgileRDD1.flatMap(lambda x: x.split(\" \"))     #To split each element by space\n",
    "agileNewWords= agileWords.filter(lambda x:x!='')\n",
    "agileResult = agileNewWords.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y) #To calculate the number of occurrences\n",
    "agileSortedResult = agileResult.sortBy(lambda x: x[1], ascending=False) # To display frequently used words\n",
    "\n",
    "print(\"The 20 most frequently used words in Agile Processess in Software Engineering and Extreme Programming are: \")\n",
    "print(\"*****************************************************************************\")\n",
    "\n",
    "agileSortedResult.take(20) # To display only first 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 04 -- Transformation and Action for Scrum\n",
    "\n",
    "scrumWords = newScrumRDD1.flatMap(lambda x: x.split(\" \"))  #To split each element by space\n",
    "scrumNewWords= scrumWords.filter(lambda x:x!='')\n",
    "scrumResult = scrumNewWords.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y) #To calculate the number of occurrences\n",
    "scrumSortedResult = scrumResult.sortBy(lambda x: x[1], ascending=False) # To display frequently used words\n",
    "\n",
    "print(\"The 20 most frequently used words in Scrum Handbook are: \")\n",
    "print(\"*****************************************************************************\") \n",
    "\n",
    "scrumSortedResult.take(20) # To display only first 20 words from Scrum file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 05 - Removing stop words\n",
    "\n",
    "#Import nltk package to remove the stop words from RDD\n",
    "\n",
    "import nltk        \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 05 - Removing stop words \n",
    "\n",
    "#Agile txt file\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "englishWords = set(stopwords.words('english'))\n",
    "unfilteredAgile = newAgileRDD1.flatMap(lambda x: x.split(\" \"))\n",
    "tempAgile= unfilteredAgile.filter(lambda x:x!='')\n",
    "agileStopWords = tempAgile.filter(lambda word: word not in englishWords and word!='') #Condition to check with stop words\n",
    "\n",
    "print(\"Word count after removing stop words in Agile Processess in Software Engineering and Extreme Programming is :\",agileStopWords.count()) #Displaying the count\n",
    "print(\"*****************************************************************************\")\n",
    "print(\"Individual words after removing stop words in Agile Processess in Software Engineering and Extreme Programming are :\\n\",agileStopWords.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 05 - Displaying distinct words\n",
    "\n",
    "#Agile txt file\n",
    "\n",
    "distinctAgileWords=agileStopWords.distinct() #Collecting only distinct words in RDD\n",
    "\n",
    "print(\"Total unique words count: \",distinctAgileWords.count())\n",
    "print(\"*****************************************************************************\")\n",
    "print(\"Unique words in Agile Processess in Software Engineering and Extreme Programming are as follows: \\n\")\n",
    "\n",
    "distinctAgileWords.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 05 - Removing stop words \n",
    "\n",
    "#Scrum txt file\n",
    "\n",
    "unfilteredScrum = newScrumRDD1.flatMap(lambda x: x.split(\" \"))\n",
    "tempScrum= unfilteredScrum.filter(lambda x:x!='')\n",
    "scrumStopWords = tempScrum.filter(lambda word: word not in englishWords and word!='') #Condition to check with stop words\n",
    "\n",
    "print(\"Number of individual word count in Scrum Handbook is :\",scrumStopWords.count()) #Displaying the count\n",
    "print(\"*****************************************************************************\")\n",
    "print(\"Individual words in Scrum Handbook are :\\n\",scrumStopWords.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 05 - Displaying distinct words\n",
    "\n",
    "#Scrum txt file\n",
    "\n",
    "distinctScrumWords=scrumStopWords.distinct() #Collecting only distinct words in RDD\n",
    "print(\"Total unique words:\",distinctScrumWords.count())\n",
    "print(\"Unique words in Scrum Handbook are as follows: \\n\")\n",
    "\n",
    "distinctScrumWords.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 06 - Find average occurrence\n",
    "\n",
    "#Agile file\n",
    "\n",
    "avgAgileCount = agileStopWords.count()/distinctAgileWords.count()\n",
    "print(\"Average occurrence of each word in Agile Processess in Software Engineering and Extreme Programming is:\",round(avgAgileCount,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 06 - Find average occurrence\n",
    "\n",
    "#Scrum file\n",
    "\n",
    "avgScrumCount = scrumStopWords.count()/distinctScrumWords.count()\n",
    "print(\"Average occurrence of each word in Scrum Handbook is:\",round(avgScrumCount,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 07 -- Exploratory Data Analysis\n",
    "\n",
    "#Book 1 is Agile\n",
    "#Book 2 is Scrum Handbook \n",
    "#1 -- Distribution of top 30 words in Book 1 and Book 2 using log scale(base 10) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "book1Count = agileStopWords.flatMap(lambda x: x.split(\" \"))\\\n",
    ".filter(lambda x:x!='')\\\n",
    ".map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\\\n",
    ".sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "book1FirstVal=book1Count.map(lambda x:x[0]) #fetching the first value from the tuple\n",
    "book1SecondVal=book1Count.map(lambda x:x[1]) #fetching second value from the tuple\n",
    "\n",
    "book2Count= scrumStopWords.flatMap(lambda x: x.split(\" \"))\\\n",
    ".filter(lambda x:x!='')\\\n",
    ".map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)\\\n",
    ".sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "book2FirstVal=book2Count.map(lambda x:x[0])\n",
    "book2SecondVal=book2Count.map(lambda x:x[1])\n",
    "\n",
    "plt.subplots(figsize=(20,5))\n",
    "plt.semilogy(book1FirstVal.take(30),book1SecondVal.take(30),label='Book 1') #using semilogarithmic graph to plot base 10\n",
    "plt.semilogy(book2FirstVal.take(30),book2SecondVal.take(30),label='Book 2')\n",
    "plt.xticks(rotation=50, ha=\"right\",fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.xlabel('Frequent Words',fontsize=17)\n",
    "plt.ylabel('Count',fontsize=17)\n",
    "plt.title('DISTRIBUTION OF BOOK 1 AND BOOK 2')\n",
    "plt.legend(loc='best',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS:\n",
    "\n",
    "The motive of using logarithmic scale is to find the occurences of words in both Agile and Scrum book. We can see there are quite lot of common words in both the books. The word Software has appeared higher number of times in book 1 than in book 2. Similarly for the other words. In this graph, I've taken only the first 30 frequently used words instead of displaying all to avoid congestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 07 -- Exploratory Data Analysis\n",
    "#2 -- Comparing 15 frequent words from Agile and Scrum file\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "bar_width = 0.5\n",
    "\n",
    "# Graph for Book 1\n",
    "plt.subplots(figsize=(10,5))\n",
    "plt.bar(book2FirstVal.take(15),book2SecondVal.take(15),bar_width, align='center', color='C0')\n",
    "plt.xticks(rotation=45, ha=\"right\",fontsize=12)\n",
    "plt.xlabel('Frequent Words')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Scrum Handbook Graph')\n",
    "\n",
    "# Graph for Book 2\n",
    "plt.subplots(figsize=(10,5))\n",
    "plt.bar(book1FirstVal.take(15),book1SecondVal.take(15),bar_width, align='center', color='C0')\n",
    "plt.xticks(rotation=45, ha=\"right\",fontsize=12)\n",
    "plt.xlabel('Frequent Words')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Agile Handbook Graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS\n",
    "\n",
    "### SCRUM HANDBOOK\n",
    "\n",
    "The first bar chart illustrates top 15 frequently used words in Scrum Handbook. It is evident that only three words(**Scrum,team,product**) has occurred more than 230 times while rest of the words are in the range of 50-150. \n",
    "\n",
    "### AGILE \n",
    "\n",
    "The second bar chart depicts the occurrences of top 15 frequently used words in Agile file. It is crystal clear that the word **Software** has appeared 850 times which is four times the average occurences of other words. This implies, there are many words in Agile file compared to Scrum handbook file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
