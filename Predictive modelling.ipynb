{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing required packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round,mean,when, count, col\n",
    "from pyspark.ml.feature import StringIndexer,VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier,GBTClassifier,LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01 -- Initializing Spark\n",
    "\n",
    "1) I have added the line SparkContext.getOrCreate() to avoid an error : \"Cannot run multiple SparkContexts at once\". If there is an existing spark context, we will reuse it instead of creating a new context.\n",
    "\n",
    "2) local[*]: run Spark locally with as many working processors as logical cores on your machine.\n",
    "\n",
    "3) The `appName` field is a name to be shown on the Sparking cluster UI. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[*]\", appName=\"FIT5202 Assignment 2\")\n",
    "\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02 -- Load,Read and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf = spark.read.csv('weatherAUS.csv',inferSchema=True, header=True)\n",
    "\n",
    "print(\"The total number of entries in the dataset is: \",weatherdf.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 03 - Delete unimportant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['Date','Location','Evaporation','Sunshine','Cloud9am','Cloud3pm','Temp9am','Temp3pm']\n",
    "weatherdf = weatherdf.select([column for column in weatherdf.columns if column not in columns_to_drop])\n",
    "\n",
    "print(\"Schema for the dataset\")\n",
    "print(\"------------------------------------------------------------------------------- \")\n",
    "\n",
    "weatherdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 04 - Printing the count of null values(NA) in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf.select([count(when(col(c)=='NA', c)).alias(c) for c in weatherdf.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 05 -- replace NA values in numeric column with mean\n",
    "\n",
    "Here I've used first()[0] to retrieve the value of mean instead of dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf = weatherdf.withColumn('MinTemp', when(col('MinTemp')=='NA',weatherdf.select(round(mean(col('MinTemp')),2))\\\n",
    "                                        .first()[0]).otherwise(col('MinTemp')))\\\n",
    "        .withColumn('MaxTemp', when(col('MaxTemp')=='NA',weatherdf.select(round(mean(col('MaxTemp')),2))\\\n",
    "                                        .first()[0]).otherwise(col('MaxTemp')))\\\n",
    "        .withColumn('Rainfall', when(col('Rainfall')=='NA',weatherdf.select(round(mean(col('Rainfall')),2))\\\n",
    "                                         .first()[0]).otherwise(col('Rainfall')))\\\n",
    "        .withColumn('WindGustSpeed', when(col('WindGustSpeed')=='NA',weatherdf.select(round(mean(col('WindGustSpeed')),2))\\\n",
    "                                        .first()[0]).otherwise(col('WindGustSpeed')))\\\n",
    "        .withColumn('WindSpeed9am', when(col('WindSpeed9am')=='NA',weatherdf.select(round(mean(col('WindSpeed9am')),2))\\\n",
    "                                         .first()[0]).otherwise(col('WindSpeed9am')))\\\n",
    "        .withColumn('WindSpeed3pm', when(col('WindSpeed3pm')=='NA',weatherdf.select(round(mean(col('WindSpeed3pm')),2))\\\n",
    "                                         .first()[0]).otherwise(col('WindSpeed3pm')))\\\n",
    "        .withColumn('Humidity9am', when(col('Humidity9am')=='NA',weatherdf.select(round(mean(col('Humidity9am')),2))\\\n",
    "                                        .first()[0]).otherwise(col('Humidity9am')))\\\n",
    "        .withColumn('Humidity3pm', when(col('Humidity3pm')=='NA',weatherdf.select(round(mean(col('Humidity3pm')),2))\\\n",
    "                                        .first()[0]).otherwise(col('Humidity3pm')))\\\n",
    "        .withColumn('Pressure9am', when(col('Pressure9am')=='NA',weatherdf.select(round(mean(col('Pressure9am')),2))\\\n",
    "                                        .first()[0]).otherwise(col('Pressure9am')))\\\n",
    "        .withColumn('Pressure3pm', when(col('Pressure3pm')=='NA',weatherdf.select(round(mean(col('Pressure3pm')),2))\\\n",
    "                                        .first()[0]).otherwise(col('Pressure3pm')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 05 -- Replace NA values in non-numeric column with frequency\n",
    "\n",
    "To get the maximum occurence, first I applied groupBy() and sorted the count in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf = weatherdf.withColumn('WindGustDir', when(col('WindGustDir')=='NA',weatherdf.select('WindGustDir')\\\n",
    "                    .groupBy('WindGustDir').count().sort('count',ascending=False).first()[0])\\\n",
    "                                 .otherwise(col('WindGustDir')))\\\n",
    ".withColumn('WindDir9am', when(col('WindDir9am')=='NA',weatherdf.select('WindDir9am')\\\n",
    "                    .groupBy('WindDir9am').count().sort('count',ascending=False).first()[0])\\\n",
    "                                .otherwise(col('WindDir9am')))\\\n",
    ".withColumn('WindDir3pm', when(col('WindDir3pm')=='NA',weatherdf.select('WindDir3pm')\\\n",
    "                    .groupBy('WindDir3pm').count().sort('count',ascending=False).first()[0])\\\n",
    "                                .otherwise(col('WindDir3pm')))\\\n",
    ".withColumn('RainToday', when(col('RainToday')=='NA',weatherdf.select('RainToday')\\\n",
    "                    .groupBy('RainToday').count().sort('count',ascending=False).first()[0])\\\n",
    "                                .otherwise(col('RainToday')))\\\n",
    ".withColumn('RainTomorrow', when(col('RainTomorrow')=='NA',weatherdf.select('RainTomorrow')\\\n",
    "                    .groupBy('RainTomorrow').count().sort('count',ascending=False).first()[0])\\\n",
    "                                .otherwise(col('RainTomorrow')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06 -- Data Transformation \n",
    "\n",
    "Splitting numeric and Non-numeric columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericColumns=['MinTemp',\n",
    "                'MaxTemp',\n",
    "                'Rainfall',\n",
    "                'WindGustSpeed',\n",
    "                'WindSpeed9am',\n",
    "                'WindSpeed3pm',\n",
    "                'Humidity9am',\n",
    "                'Humidity3pm',\n",
    "                'Pressure9am',\n",
    "                'Pressure3pm']\n",
    "\n",
    "nonNumericColumns=['WindGustDir',\n",
    "                   'WindDir9am',\n",
    "                   'WindDir3pm',\n",
    "                   'RainToday',\n",
    "                   'RainTomorrow']\n",
    "\n",
    "#Here I am converting numeric columns into double type\n",
    "for col_name in numericColumns:  \n",
    "    weatherdf=weatherdf.withColumn(col_name, col(col_name).cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06 -- Data Transformation \n",
    "\n",
    "Converting non-numeric columns into numeric using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in nonNumericColumns ]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "weatherdf = pipeline.fit(weatherdf).transform(weatherdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06 -- Data Transformation\n",
    "\n",
    "I'm using VectorAssembler for data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\n",
    "                                \"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\n",
    "                                \"Pressure3pm\"],\n",
    "                       outputCol=\"features\")\n",
    "\n",
    "weatherdf=assembler.transform(weatherdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since non numeric columns are subsequently converted to numeric using StringIndexer, I'm removing the original non-numeric columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherdf = weatherdf.select([column for column in weatherdf.columns if column not in nonNumericColumns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 07 - Splitting the data randomly between 70% and 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = weatherdf.randomSplit([0.7, 0.3], seed = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08 - Computing accuracy using machine learning algorithms\n",
    "### 8.1 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"RainTomorrow_index\", featuresCol=\"features\")\n",
    "dtModel = dt.fit(trainingData)\n",
    "\n",
    "dtPredictions = dtModel.transform(testData)\n",
    "\n",
    "dtPredictions.select(\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\\\n",
    "                    \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"WindGustDir_index\",\\\n",
    "                    \"WindDir9am_index\",\"WindDir3pm_index\",\"RainToday_index\",\"probability\",\"prediction\")\\\n",
    "                .orderBy(\"probability\", ascending=False).show(5)\n",
    "\n",
    "dtEvaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "decisionTreeAccuracy = (dtEvaluator.evaluate(dtPredictions))*100\n",
    "\n",
    "\n",
    "print(\"Decision Tree Accuracy is: \"+\" \"+\"%.2f\" % decisionTreeAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08\n",
    "### 8.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"RainTomorrow_index\",\\\n",
    "featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "rfModel = rf.fit(trainingData)\n",
    "\n",
    "rfPredictions = rfModel.transform(testData)\n",
    "\n",
    "rfPredictions.select(\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\\\n",
    "                    \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"WindGustDir_index\",\\\n",
    "                    \"WindDir9am_index\",\"WindDir3pm_index\",\"RainToday_index\",\"probability\",\"prediction\")\\\n",
    "                .orderBy(\"probability\", ascending=False).show(5)\n",
    "\n",
    "rfEvaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "randomForestAccuracy = (rfEvaluator.evaluate(rfPredictions))*100\n",
    "\n",
    "print(\"Random Forest Accuracy is: \"+\" \"+\"%.2f\" % randomForestAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08\n",
    "\n",
    "### 8.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"RainTomorrow_index\", featuresCol=\"features\", maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "lrPredictions = lrModel.transform(testData)\n",
    "\n",
    "lrPredictions.select(\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\\\n",
    "                    \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"WindGustDir_index\",\\\n",
    "                    \"WindDir9am_index\",\"WindDir3pm_index\",\"RainToday_index\",\"probability\",\"prediction\")\\\n",
    "                .orderBy(\"probability\", ascending=False).show(5)\n",
    "\n",
    "lrEvaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "logisticRegressionAccuracy = (lrEvaluator.evaluate(lrPredictions))*100\n",
    "\n",
    "print(\"Logistic Regression Accuracy is: \"+\" \"+\"%.2f\" % logisticRegressionAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08\n",
    "\n",
    "### 8.4 GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=\"RainTomorrow_index\", featuresCol=\"features\",maxIter=10)\n",
    "gbtModel = gbt.fit(trainingData)\n",
    "gbtPredictions = gbtModel.transform(testData)\n",
    "\n",
    "gbtPredictions.select(\"MinTemp\",\"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\\\n",
    "                    \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"WindGustDir_index\",\\\n",
    "                    \"WindDir9am_index\",\"WindDir3pm_index\",\"RainToday_index\",\"probability\",\"prediction\")\\\n",
    "                .orderBy(\"probability\", ascending=False).show(5)\n",
    "\n",
    "gbtEvaluator = MulticlassClassificationEvaluator(labelCol=\"RainTomorrow_index\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "gbtAccuracy = (gbtEvaluator.evaluate(gbtPredictions))*100\n",
    "\n",
    "print(\"Gradient Boosting Accuracy is: \"+\" \"+\"%.2f\" % gbtAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08 - Comparing accuracy using bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bar_width = 0.5\n",
    "\n",
    "classificationList=('Decision Tree','Random Forest','Logistic Regression','GBT')\n",
    "y_pos = np.arange(len(classificationList))\n",
    "accuracyValues = [decisionTreeAccuracy,randomForestAccuracy,logisticRegressionAccuracy,gbtAccuracy]\n",
    "\n",
    "plt.subplots(figsize=(10,5))\n",
    "plt.style.use('ggplot')\n",
    "plt.bar(y_pos,accuracyValues,bar_width, align='center', color='C0')\n",
    "plt.xticks(y_pos,classificationList,fontsize=14)\n",
    "plt.xlabel('Classfication Techniques',fontsize=14)\n",
    "plt.ylabel('Accuracy(%)',fontsize=14)\n",
    "plt.title('COMPARISON OF MACHINE LEARNING ALGORITHMS ACCURACY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 08 - ANALYSIS\n",
    "\n",
    "The accuracy graph for machine learning classification algorithms is illustrated above. It is clear that GBT generated high accuracy followed by Random Forest and Decision Tree with marginal differences. Finally, Logistic Regression presume to be less accurate compared to other three algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 - Calculate confusion matrix\n",
    "\n",
    "- **True Positive (TP)** : Observation is positive, and is predicted to be positive.\n",
    "- **False Negative (FN)** : Observation is positive, but is predicted negative.\n",
    "- **True Negative (TN)** : Observation is negative, and is predicted to be negative.\n",
    "- **False Positive (FP)** : Observation is negative, but is predicted positive.\n",
    "\n",
    "In this case, positive is 1.0 and negative is 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(predictions):\n",
    "    \n",
    "    TN=predictions.filter('prediction = 0.0 AND RainTomorrow_index = 0.0').count()\n",
    "    FN=predictions.filter('prediction = 0.0 AND RainTomorrow_index = 1.0').count()\n",
    "    TP=predictions.filter('prediction = 1.0 AND RainTomorrow_index = 1.0').count()\n",
    "    FP=predictions.filter('prediction = 1.0 AND RainTomorrow_index = 0.0').count()\n",
    "    \n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = 2*((precision*recall)/(precision+recall))\n",
    "    return('precision = {:.2f}, recall = {:.2f}, f1Score = {:.2f}'.format(precision, recall, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for machine learning classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix for Decision Tree are : \",confusionMatrix(dtPredictions))\n",
    "print(\"Confusion Matrix for Random Forest are : \",confusionMatrix(rfPredictions))\n",
    "print(\"Confusion Matrix for Logistic Regression are : \",confusionMatrix(lrPredictions))\n",
    "print(\"Confusion Matrix for Gradient Boosting are : \",confusionMatrix(gbtPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Accuacy can be improved? \n",
    "\n",
    "**NOTE: The below mentioned points are based on my understanding.** \n",
    "\n",
    "1. If you are using wrong or irrelevant parameter, you hardly get good accuracy. Henceforth, selecting right parametes realted to target variable plays a pivotal role in deciding accuracy. \n",
    "2. Cross Validation could help in this regard. It will leave the sample where you do not want to train this model. However it tests the model on these sample before finalizing the model. \n",
    "3. Although, there are 140k records in this dataset, predicting a weather is huge task. Additional data could have helped to boost the accuracy. \n",
    "4. Randomly splitting test and training data may impact accuracy. So adequate attention has to be given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
